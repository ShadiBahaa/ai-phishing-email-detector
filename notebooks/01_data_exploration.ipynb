{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288f23f",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Update this path to your dataset location\n",
    "df = pd.read_csv('../data/raw/emails.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19053815",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5768bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nTotal missing: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7bdcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution\n",
    "print(\"Label distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(df['label'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6281221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Count plot\n",
    "labels = ['Legitimate', 'Phishing']\n",
    "counts = df['label'].value_counts().sort_index()\n",
    "\n",
    "axes[0].bar(labels, counts, color=['green', 'red'])\n",
    "axes[0].set_title('Email Distribution by Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "for i, v in enumerate(counts):\n",
    "    axes[0].text(i, v + 50, str(v), ha='center')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(counts, labels=labels, autopct='%1.1f%%', colors=['green', 'red'])\n",
    "axes[1].set_title('Email Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb42c1",
   "metadata": {},
   "source": [
    "## 3. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b024bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text lengths\n",
    "df['text_length'] = df['email_text'].str.len()\n",
    "df['word_count'] = df['email_text'].str.split().str.len()\n",
    "\n",
    "# Statistics by class\n",
    "print(\"Text length statistics:\")\n",
    "print(df.groupby('label')['text_length'].describe())\n",
    "\n",
    "print(\"\\nWord count statistics:\")\n",
    "print(df.groupby('label')['word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da825a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize text length distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Text length distribution\n",
    "for label, name, color in [(0, 'Legitimate', 'green'), (1, 'Phishing', 'red')]:\n",
    "    subset = df[df['label'] == label]['text_length']\n",
    "    axes[0].hist(subset, bins=50, alpha=0.6, label=name, color=color)\n",
    "\n",
    "axes[0].set_xlabel('Text Length (characters)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Text Length Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Word count distribution\n",
    "for label, name, color in [(0, 'Legitimate', 'green'), (1, 'Phishing', 'red')]:\n",
    "    subset = df[df['label'] == label]['word_count']\n",
    "    axes[1].hist(subset, bins=50, alpha=0.6, label=name, color=color)\n",
    "\n",
    "axes[1].set_xlabel('Word Count')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Word Count Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795f69a",
   "metadata": {},
   "source": [
    "## 4. URL and Email Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count URLs in emails\n",
    "def count_urls(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return len(re.findall(r'http\\S+|www\\.\\S+', text))\n",
    "\n",
    "def count_emails(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return len(re.findall(r'\\S+@\\S+', text))\n",
    "\n",
    "df['url_count'] = df['email_text'].apply(count_urls)\n",
    "df['email_count'] = df['email_text'].apply(count_emails)\n",
    "\n",
    "print(\"URL count by class:\")\n",
    "print(df.groupby('label')['url_count'].describe())\n",
    "\n",
    "print(\"\\nEmail address count by class:\")\n",
    "print(df.groupby('label')['email_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef874180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize URL presence\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# URL count by class\n",
    "df_url_summary = df.groupby('label')['url_count'].mean()\n",
    "axes[0].bar(['Legitimate', 'Phishing'], df_url_summary, color=['green', 'red'])\n",
    "axes[0].set_title('Average URL Count by Class')\n",
    "axes[0].set_ylabel('Average URLs per Email')\n",
    "\n",
    "# Emails with URLs\n",
    "url_presence = df.groupby('label').apply(lambda x: (x['url_count'] > 0).mean() * 100)\n",
    "axes[1].bar(['Legitimate', 'Phishing'], url_presence, color=['green', 'red'])\n",
    "axes[1].set_title('Percentage of Emails with URLs')\n",
    "axes[1].set_ylabel('Percentage (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa2bb06",
   "metadata": {},
   "source": [
    "## 5. Common Words Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69724627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "def get_top_words(texts, n=20):\n",
    "    \"\"\"Get most common words from texts.\"\"\"\n",
    "    words = []\n",
    "    for text in texts:\n",
    "        if pd.isna(text):\n",
    "            continue\n",
    "        # Simple tokenization\n",
    "        text = text.lower()\n",
    "        text = ''.join(c if c.isalpha() or c.isspace() else ' ' for c in text)\n",
    "        words.extend(text.split())\n",
    "    \n",
    "    # Remove stopwords (simple list)\n",
    "    stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been',\n",
    "                 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\n",
    "                 'would', 'could', 'should', 'may', 'might', 'must', 'shall',\n",
    "                 'to', 'of', 'in', 'for', 'on', 'with', 'at', 'by', 'from',\n",
    "                 'as', 'into', 'through', 'during', 'before', 'after', 'above',\n",
    "                 'below', 'and', 'but', 'or', 'nor', 'so', 'yet', 'both',\n",
    "                 'either', 'neither', 'not', 'only', 'own', 'same', 'than',\n",
    "                 'too', 'very', 's', 't', 'can', 'just', 'don', 'now', 'i',\n",
    "                 'you', 'your', 'we', 'our', 'they', 'their', 'this', 'that',\n",
    "                 'it', 'its', 'if', 'then', 'else', 'when', 'there', 'here'}\n",
    "    \n",
    "    words = [w for w in words if w not in stopwords and len(w) > 2]\n",
    "    \n",
    "    return Counter(words).most_common(n)\n",
    "\n",
    "# Get top words for each class\n",
    "phishing_words = get_top_words(df[df['label'] == 1]['email_text'])\n",
    "legitimate_words = get_top_words(df[df['label'] == 0]['email_text'])\n",
    "\n",
    "print(\"Top words in PHISHING emails:\")\n",
    "for word, count in phishing_words:\n",
    "    print(f\"  {word}: {count}\")\n",
    "\n",
    "print(\"\\nTop words in LEGITIMATE emails:\")\n",
    "for word, count in legitimate_words:\n",
    "    print(f\"  {word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaeaf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top words\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Phishing words\n",
    "words, counts = zip(*phishing_words[:15])\n",
    "axes[0].barh(words, counts, color='red', alpha=0.7)\n",
    "axes[0].set_xlabel('Frequency')\n",
    "axes[0].set_title('Top Words in Phishing Emails')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Legitimate words\n",
    "words, counts = zip(*legitimate_words[:15])\n",
    "axes[1].barh(words, counts, color='green', alpha=0.7)\n",
    "axes[1].set_xlabel('Frequency')\n",
    "axes[1].set_title('Top Words in Legitimate Emails')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c7350",
   "metadata": {},
   "source": [
    "## 6. Sample Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2559f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample phishing emails\n",
    "print(\"=\" * 50)\n",
    "print(\"SAMPLE PHISHING EMAILS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, row in df[df['label'] == 1].sample(3).iterrows():\n",
    "    print(f\"\\n--- Email #{i} ---\")\n",
    "    print(row['email_text'][:500] + \"...\" if len(row['email_text']) > 500 else row['email_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample legitimate emails\n",
    "print(\"=\" * 50)\n",
    "print(\"SAMPLE LEGITIMATE EMAILS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, row in df[df['label'] == 0].sample(3).iterrows():\n",
    "    print(f\"\\n--- Email #{i} ---\")\n",
    "    print(row['email_text'][:500] + \"...\" if len(row['email_text']) > 500 else row['email_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7961bf8",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "Document your key findings here after running the analysis:\n",
    "\n",
    "1. **Class Balance**: [Balanced/Imbalanced?]\n",
    "2. **Text Length**: [How do phishing vs legitimate compare?]\n",
    "3. **URL Presence**: [More URLs in phishing emails?]\n",
    "4. **Key Words**: [What distinguishes phishing from legitimate?]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
